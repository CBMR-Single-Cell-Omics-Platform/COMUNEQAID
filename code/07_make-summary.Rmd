---
title: "The mega-awesome-html"
output: 
  html_document: 
    #theme: lumen
    toc: true
    theme: united
mainfont: Helvetica
---

```{r Packages}
suppressPackageStartupMessages({
  library(knitr)
  library(htmltools)
  library(tidyverse)
  library(Seurat)
  library(viridis)
  library(kableExtra)
  library(Biobase)
  library(plotly)
})
```

```{r setup, include=FALSE}
opts_chunk$set(echo = F, warning = F, message = F, cache = F, fig.width = 12, fig.height = 8)
opts_knit$set(root.dir = '~/projects/COMUNEQAID_dev/COMUNEQAID')
tagList(plotly:::plotly_empty())
```

```{r Functions}
library(yaml)
setClass("mock_snakemake", representation(config = "list"))

config <- yaml::read_yaml(
  '/maps/projects/scop/data/SCOP_2021_0142_test/output/2023-08-30_brain-cell-line_human/COMUNEQAID_v2.0/COMUNEQAID-pipeline/2023-08-30_brain-cell-line_human.yml'
  )
snakemake <- new("mock_snakemake", config = config)

snakemake@config
# Shared functions
source('code/shared.R')

# Paths
project.path <- file.path(
  snakemake@config[['project_path']],
  snakemake@config[['scop_id']])

com.path <- file.path(
  project.path,
  'output',
  snakemake@config[['com_id']],
  snakemake@config[['pipeline_version']])

aggr.path <- file.path(
  com.path,
  'aggregated')

plot.path <- file.path(
  com.path,
  'plots')

summary.path <- file.path(
  com.path,
  'summary')

# Files
log.file <- file.path(
  plot.path,
  paste0(date.and.time,'.log'))


# Metadata
suppressMessages({
  omnisheet <- 
    as_tibble(snakemake@config[['sample_sheet']]) %>% 
    full_join(as_tibble(snakemake@config[['sample2reaction']])) %>% 
    full_join(as_tibble(snakemake@config[['reaction_sheet']])) %>% 
    full_join(as_tibble(snakemake@config[['reaction2library']])) %>% 
    full_join(as_tibble(snakemake@config[['library_sheet']])) %>% 
    full_join(as_tibble(snakemake@config[['library2sequencing']])) %>% 
    full_join(as_tibble(snakemake@config[['sequencing_sheet']]))

  rnxsheet.rnx2lib <-
    full_join(as_tibble(snakemake@config[['reaction_sheet']]),
              as_tibble(snakemake@config[['reaction2library']]))
  
  seq.sheet <-
    as_tibble(snakemake@config[['sequencing_sheet']])
  
  rnx.sheet <-
    as_tibble(snakemake@config[['reaction_sheet']])
  
  samplesheet.sample2rnx <- full_join(as_tibble(snakemake@config[['sample_sheet']]),
            as_tibble(snakemake@config[['sample2reaction']]))
})

```

## RNA {.tabset}
```{r, results='asis', cache.lazy = FALSE}
# tmp <- stat.tib.10x[1,]
# 
# ## SUMMARY
# #table.var.n.cells.est <- 
# #table.var.mean.read.pr.cell <- 
# #table.var.median.UMI.pr.cell <- x
# 
# # SEQUENCING
# Number of reads
# Number of short reads skipped
# valid barcodes
# Valid UMIS
# Sequencing saturation
# Q30 bases in barcode
# Q30 bases in umi
# 
# # MAPPING
# #Reads mapped to genome
# lepip.af.map$num_mapped/lepip.af.map$num_processed*100
# Reads mapped confidently to genome
# Reads mapped confidently to intergenic
# Reads mapped confidently to intronic regions
# Reads mapped confidently to exonic regions
# Reads mapped confidently to transcriptome
# Reads mapped antisense to gene
# 
# #####
# # CELLS
# # estimated number of cells
# length(unique(featDump.10x[featDump.10x[['CB']] %in% cells.ranks,][['CB']]))
# # fraction reads in cell
# round(sum(featDump.10x[featDump.10x[['CB']] %in% cells.ranks,][['MappedReads']]) / tmp.pool[['READS (10x)']] * 100, 1)
# # mean reads per cell
# round(mean(featDump.10x[featDump.10x[['CB']] %in% cells.ranks,][['MappedReads']]))
# #median UMI counts per cell
# round(median(featDump.10x[featDump.10x[['CB']] %in% cells.ranks,][['DeduplicatedReads']]))
# #median genes per cell
# round(median(featDump.10x[featDump.10x[['CB']] %in% cells.ranks,][['NumGenesExpressed']]))
# #Total Genes Detected
# table(rowSums(tmp.af.a10@assays$RNA@counts) > 0)[[2]]                                       
# #####

```


# FASTQ generation {.tabset}
```{r FASTQ generation, results='asis'}
for (i in row_number(seq.sheet)) {
  
  seq.id <- seq.sheet[1,][['sequencing_id']]
  bcl.folder <- seq.sheet[1,][['bcl_folder']]

  fastq.stats.path <- file.path(
    snakemake@config[['project_path']],
    snakemake@config[['scop_id']],
    snakemake@config[['fastq_path']],
    bcl.folder,
    'metadata')
  
  df.unknown.barcodes <- read.csv(file.path(fastq.stats.path,'unknown-barcodes.csv'))
  df.read.demultiplexing <- read.csv(file.path(fastq.stats.path,'read-demultiplexing.csv'))
  
  p.unknown.barcodes <- make_plot_top10bcl(df.unknown.barcodes)
  p.read.demultiplexing <- make_plot_bclDistribution(df.read.demultiplexing)  
  

  catHeader(bcl.folder, 2)
  print(p.unknown.barcodes)

  catHeader(bcl.folder, 2)
  print(p.read.demultiplexing)
  
  ###
  # catHeader(substring(str_split(bcl.file, '.csv')[[1]][[1]], 13), 2)
  # 
  # df <- read.csv(file.path(dir.fstq.outs,bcl.file))
  # plot <- make_plot_top10bcl(df)
  # 
  # plot <- plotly::ggplotly(plot, tooltip = c("text", "x", "y", "colour"))
  # plot %>%  htmltools::tagList() %>% print()
  # 
  # print(plot)
}
```

## bcl2fastq - read distribution
```{r bcl2fastq - read distribution, results='asis', cache.lazy = FALSE}
read.df.all <- read_csv(file.path(dir.fstq.outs,'read-distribution_bcl2fastq.csv'))

plot <- make_plot_bclDistribution(read.df.all)

#plot <- plotly::ggplotly(plot, tooltip = c("text", "x", "y", "colour"))
#plot %>%  htmltools::tagList() %>% print()

print(plot)
```

# Cell Calling (RNA) {.tabset}
## Barcode rank plot {.tabset}
```{r Barcode rank plot, results='asis', cache.lazy = FALSE}
for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 3)
  
  df <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'barcode-rank.csv'))
  annot <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'barcode-rank-annotation.csv'))
  
  plot <- make_plot_barcodeRanks(df,annot,bc.df.ref)
  
  #plot <- plotly::ggplotly(plot, tooltip = c("text", "x", "y", "colour"))
  #plot %>%  htmltools::tagList() %>% print()
  
  print(plot)
}
```

## Histogram {.tabset}
```{r Histogram, results='asis', cache.lazy = FALSE}
for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 3)
  
  df <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'barcode-rank.csv'))
  annot <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'barcode-rank-annotation.csv'))
  
  plot <- make_plot_barcodeHist(df, annot)
  
  #plot <- plotly::ggplotly(plot, tooltip = c("text", "x", "y", "colour"))
  #plot %>%  htmltools::tagList() %>% print()
  
  print(plot)
}
```

# Cell calling (HTO) {.tabset}

## Inter-HTO calling {.tabset}
Description of "Inter-HTO calling"

### Individual HTO distributions {.tabset}
```{r, results='asis', cache.lazy = FALSE}
for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 4)
  
  hto.data.long <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'hto-data-long.csv'))
  hto_mcl.cutoff <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'hto-mcl-cutoff.csv'))
  
  p <- make_plot_htoThresh(hto.data.long,hto_mcl.cutoff)
  
  print(p)
}
```

### HTO expression {.tabset}
#### Global classification {.tabset}
```{r, results='asis', cache.lazy = FALSE}
for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 5)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  p <- make_plot_htoVlnGlobal(meta.data)
  
  print(p)

}
```

#### Sample classification {.tabset}
```{r, results='asis', cache.lazy = FALSE}
for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 5)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  p <- make_plot_htoVlnIndividual(meta.data)
  
  print(p)
}
```

### Clustering {.tabset}
#### Global classification {.tabset}
```{r tSNE HTO (global), results='asis', cache.lazy = FALSE}
for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 5)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  p <- make_plot_htotsne(meta.data, 'Global')
  
  print(p)

}
```

#### Sample classification {.tabset}
```{r tSNE HTO (sample), results='asis', cache.lazy = FALSE}
for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 5)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  p <- make_plot_htotsne(meta.data, 'Individual')
  
  print(p)

}
```

### Inter-HTO classification {.tabset}
```{r, results='asis', cache.lazy = FALSE}
catHeader_w_tabset('UMAP', 4)

for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 7)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  p <- make_plot_InfDoubl_class(meta.data, reduction = 'UMAP')
  
  print(p)
}

catHeader_w_tabset('PCA', 4)

for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 7)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  p <- make_plot_InfDoubl_class(meta.data, reduction = 'PCA')
  
  print(p)
}
```

## Intra-HTO doublet calling {.tabset}
Description of "Intra-HTO calling"

### Intra-HTO doublets from doublet RNA profile {.tabset}
```{r, results='asis', cache.lazy = FALSE}
catHeader_w_tabset('UMAP', 4)

for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 5)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  p <- make_plot_InfDoubl_std(meta.data, reduction = 'UMAP')
  
  print(p)
}

catHeader_w_tabset('PCA', 4)

for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 5)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  p <- make_plot_InfDoubl_std(meta.data, reduction = 'PCA')
  
  print(p)
}
```

### Proportion of neighboring doublets {.tabset}
```{r, results='asis', cache.lazy = FALSE}
catHeader_w_tabset('UMAP', 4)

for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 5)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  p <- make_plot_InfDoubl_prop(meta.data, reduction = 'UMAP')
  p <- p + scale_color_viridis()
  print(p)
}

catHeader_w_tabset('PCA', 4)

for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 5)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  p <- make_plot_InfDoubl_prop(meta.data, reduction = 'PCA')
  p <- p + scale_color_viridis()
  print(p)
}
```

### Doublets from neighbor proportion threshold {.tabset}
```{r, results='asis', cache.lazy = FALSE}
for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 4)
  
  doub.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'inf-doubl-table.csv'))
  
  p <- make_plot_InfDoubl_knee(doub.data)
  
  print(p)
}
```

### Intra-HTO doublets profile + proportion {.tabset}
```{r, results='asis', cache.lazy = FALSE}
catHeader_w_tabset('UMAP', 4)

for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 5)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  p <- make_plot_InfDoubl_cut(meta.data, reduction = 'UMAP')
  
  print(p)
}

catHeader_w_tabset('PCA', 4)

for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 5)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  p <- make_plot_InfDoubl_cut(meta.data, reduction = 'PCA')
  
  print(p)
}
```

### RNA Violin plot - HTO {.tabset}
```{r, results='asis', cache.lazy = FALSE}
for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 4)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  mutate(meta.data,
         doublet_type = factor(ifelse(doublet == T, 'Inter-HTO doublet',
                                      ifelse(predicted_dub_std == T, 'Intra-HTO doublet (RNA profile)',
                                             ifelse(predicted_dub_cut == T, 'Intra-HTO doublet (neighbouring doublets)',
                                                    ifelse(HTO_mcl_classification.global == 'Negative', 'Negative',
                                                           'Singlet')))),
                               levels = c('Negative','Singlet','Inter-HTO doublet','Intra-HTO doublet (RNA profile)','Intra-HTO doublet (neighbouring doublets)'))) -> meta.data

  p <- make_plot_htoVlnAll(meta.data)
  
  print(p)
}
```

# Summarize all {.tabset}

## Violin {.tabset}

```{r, results='asis', cache.lazy = FALSE}


for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 3)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-sing-metadata.csv'))
  
  p <- make_plot_rnaVln(meta.data)
  
  print(p)
}
```

## UMAP {.tabset}
```{r, results='asis', cache.lazy = FALSE}
for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 3)
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-sing-metadata.csv'))
  
  p <- make_plot_ff_class(meta.data)
  
  print(p)
}
```


```{r, results='asis', cache.lazy = FALSE}

df <- data.frame(Type = character(),
                 CountSum = double(),
                 CountPer = double(),
                 CountTot = double(),
                 Pool = character())

df.hto <- data.frame(Library = character(),
                     Class = character(),
                     CountPer = double(),
                     Labelpos = double(),
                     Pool = character())

for (i in seq(n.pools)) {
  
  tmp.pool <- pool.table[i,]
  
  pool.10x <- tmp.pool[['Index (10x)']]
  
  bc.data <- read.csv(file.path(dir.pipe.outs,pool.10x,'barcode-rank.csv'))
  
  bcs.called <- bc.data[bc.data[['State']] == 'Called',][['Barcode']]
  bcs.uncalled <- bc.data[bc.data[['State']] == 'Uncalled',][['Barcode']]
  
  tmp.counts.spl.called <- sum(bc.data[bc.data[['State']] == 'Called',][['nCount_spliced']])
  tmp.counts.spl.uncalled <- sum(bc.data[bc.data[['State']] == 'Uncalled',][['nCount_spliced']])
  tmp.counts.uns.called <- sum(bc.data[bc.data[['State']] == 'Called',][['nCount_unspliced']])
  tmp.counts.uns.uncalled <- sum(bc.data[bc.data[['State']] == 'Uncalled',][['nCount_unspliced']])
  tmp.counts.tot.called <- tmp.counts.spl.called + tmp.counts.uns.called
  tmp.counts.tot.uncalled <- tmp.counts.spl.uncalled + tmp.counts.uns.uncalled
  
  tmp.percen.spl.called <- round(tmp.counts.spl.called/tmp.counts.tot.called*100)
  tmp.percen.spl.uncalled <- round(tmp.counts.spl.uncalled/tmp.counts.tot.uncalled*100)
  tmp.percen.uns.called <- round(tmp.counts.uns.called/tmp.counts.tot.called*100)
  tmp.percen.uns.uncalled <- round(tmp.counts.uns.uncalled/tmp.counts.tot.uncalled*100)
  
  tmp.df <- data.frame(ReadType = c('Spliced','Unspliced','Spliced','Unspliced'),
                       CellType = c('Called','Called','Uncalled','Uncalled'),
                       CountSum = c(tmp.counts.spl.called,tmp.counts.uns.called,tmp.counts.spl.uncalled,tmp.counts.uns.uncalled),
                       CountPer = c(tmp.percen.spl.called,tmp.percen.uns.called,tmp.percen.spl.uncalled,tmp.percen.uns.uncalled),
                       CountTot = c(tmp.counts.tot.called,tmp.counts.tot.called,tmp.counts.tot.uncalled,tmp.counts.tot.uncalled),
                       Pool = c(pool.10x,pool.10x,pool.10x,pool.10x))
  
  df <- rbind(df,tmp.df)
  
  if (var.wofl == '10x + HTO') {
    
    pool.hto <- tmp.pool[['Index (HTO)']]
    
    bc.data.hto <- read.csv(file.path(dir.pipe.outs,pool.10x,'col-sums-hto.csv'))
    meta.data <- read.csv(file.path(dir.pipe.outs,pool.10x,'seurat-full-metadata.csv'))
    
    bcs.negative <- rownames(meta.data[meta.data[['HTO_mcl_classification.global']] == 'Negative',])
    bcs.singlet <- rownames(meta.data[meta.data[['HTO_mcl_classification.global']] == 'Singlet',])
    bcs.doublet <- rownames(meta.data[meta.data[['HTO_mcl_classification.global']] == 'Doublet',])
    
    tmp.counts.rna.called <- tmp.counts.tot.called
    tmp.counts.rna.uncalled <- tmp.counts.tot.uncalled
    tmp.counts.rna.negative <- sum(bc.data[bc.data[['Barcode']] %in% bcs.negative,][['nCount_RNA']])
    tmp.counts.rna.singlet <- sum(bc.data[bc.data[['Barcode']] %in% bcs.singlet,][['nCount_RNA']])
    tmp.counts.rna.doublet <- sum(bc.data[bc.data[['Barcode']] %in% bcs.doublet,][['nCount_RNA']])
    tmp.counts.rna.total <- tmp.counts.rna.called + tmp.counts.rna.uncalled
    
    bc.data
    
    tmp.counts.hto.called <- sum(bc.data.hto[rownames(bc.data.hto) %in% bcs.called,])
    tmp.counts.hto.uncalled <- sum(bc.data.hto[rownames(bc.data.hto) %!in% bcs.called,])
    tmp.counts.hto.negative <- sum(bc.data.hto[rownames(bc.data.hto) %in% bcs.negative,])
    tmp.counts.hto.singlet <- sum(bc.data.hto[rownames(bc.data.hto) %in% bcs.singlet,])
    tmp.counts.hto.doublet <- sum(bc.data.hto[rownames(bc.data.hto) %in% bcs.doublet,])
    tmp.counts.hto.total <- tmp.counts.hto.called + tmp.counts.hto.uncalled
    
    tmp.percen.rna.uncalled <- round(tmp.counts.rna.uncalled/tmp.counts.rna.total*100)
    tmp.percen.rna.negative <- round(tmp.counts.rna.negative/tmp.counts.rna.total*100)
    tmp.percen.rna.singlet <- round(tmp.counts.rna.singlet/tmp.counts.rna.total*100)
    tmp.percen.rna.doublet <- round(tmp.counts.rna.doublet/tmp.counts.rna.total*100)
    
    tmp.percen.hto.uncalled <- round(tmp.counts.hto.uncalled/tmp.counts.hto.total*100)
    tmp.percen.hto.negative <- round(tmp.counts.hto.negative/tmp.counts.hto.total*100)
    tmp.percen.hto.singlet <- round(tmp.counts.hto.singlet/tmp.counts.hto.total*100)
    tmp.percen.hto.doublet <- round(tmp.counts.hto.doublet/tmp.counts.hto.total*100)
    
    tmp.labpos.rna.uncalled <- tmp.counts.rna.uncalled/2
    tmp.labpos.rna.negative <- tmp.counts.rna.uncalled + tmp.counts.rna.negative/2
    tmp.labpos.rna.singlet <- tmp.counts.rna.uncalled + tmp.counts.rna.negative + tmp.counts.rna.singlet/2
    tmp.labpos.rna.doublet <- tmp.counts.rna.uncalled + tmp.counts.rna.negative + tmp.counts.rna.singlet + tmp.counts.rna.doublet/2
    
    tmp.labpos.hto.uncalled <- tmp.counts.hto.uncalled/2
    tmp.labpos.hto.negative <- tmp.counts.hto.uncalled + tmp.counts.hto.negative/2
    tmp.labpos.hto.singlet <- tmp.counts.hto.uncalled + tmp.counts.hto.negative + tmp.counts.hto.singlet/2
    tmp.labpos.hto.doublet <- tmp.counts.hto.uncalled + tmp.counts.hto.negative + tmp.counts.hto.singlet + tmp.counts.hto.doublet/2
    
    tmp.df.hto <- data.frame(Library = c('RNA','RNA','RNA','RNA',
                                         'HTO','HTO','HTO','HTO'),
                             Class = c('Uncalled','Negative','Singlet','Doublet',
                                       'Uncalled','Negative','Singlet','Doublet'),
                             CountSum = c(tmp.counts.rna.uncalled,tmp.counts.rna.negative,tmp.counts.rna.singlet,tmp.counts.rna.doublet,
                                          tmp.counts.hto.uncalled,tmp.counts.hto.negative,tmp.counts.hto.singlet,tmp.counts.hto.doublet),
                             CountPer = c(tmp.percen.rna.uncalled,tmp.percen.rna.negative,tmp.percen.rna.singlet,tmp.percen.rna.doublet,
                                          tmp.percen.hto.uncalled,tmp.percen.hto.negative,tmp.percen.hto.singlet,tmp.percen.hto.doublet),
                             Labelpos = c(tmp.labpos.rna.uncalled,tmp.labpos.rna.negative,tmp.labpos.rna.singlet,tmp.labpos.rna.doublet,
                                          tmp.labpos.hto.uncalled,tmp.labpos.hto.negative,tmp.labpos.hto.singlet,tmp.labpos.hto.doublet),
                             Pool = c(pool.10x,pool.10x,pool.10x,pool.10x,
                                      pool.hto,pool.hto,pool.hto,pool.hto))
    
    df.hto <- rbind(df.hto,tmp.df.hto)
  }
}
df[['Labelpos']] <- ifelse(df[['ReadType']] == 'Unspliced',
                           df[['CountSum']]/2, df[['CountTot']] - df[['CountSum']]/2)

p <- ggplot(data = df, aes(x = Pool, y = CountSum, fill = ReadType)) +
  geom_bar(stat = 'identity') + 
  geom_text(aes(label = paste0(CountPer,'%'),y = Labelpos),size = 3) +
  coord_flip() + ggtitle('Spliced/Unspliced - Counts') +
  xlab('Index') + ylab('Summed counts') + scale_fill_discrete(name = 'Read type') +
  facet_wrap(~CellType, nrow = 2) +
  scale_fill_manual(values = softPallet(2)) +
  theme_minimal(base_size = base.size) +
  theme(text = element_text(family = plotting.font))

print(p)

if (var.wofl == '10x + HTO') {
  p.rna <- ggplot(data = df.hto[df.hto[['Library']] == 'RNA',],
                  aes(x = Pool,
                      y = CountSum,
                      fill = factor(Class, levels = c('Doublet','Singlet','Negative','Uncalled')))) +
    geom_bar(stat = 'identity') + 
    geom_text(aes(label = paste0(CountPer, '%'),
                  y = Labelpos),
              size = 3) +
    coord_flip() + ggtitle('Read distribution by HTO class', subtitle = 'RNA reads') +
    xlab('Index') + ylab('Summed counts') + scale_fill_discrete(name = 'Classification') +
    scale_fill_manual(values = c(my.cols[['Doublet']],my.cols[['Singlet']],my.cols[['Negative']],my.cols[['Uncalled']])) +
    labs(fill = 'Classification') + 
    theme_minimal(base_size = base.size) +
    theme(text = element_text(family = plotting.font))
  
  p.hto <- ggplot(data = df.hto[df.hto[['Library']] == 'HTO',],
                  aes(x = Pool, y = CountSum, fill = factor(Class, levels = c('Doublet','Singlet','Negative','Uncalled')))) +
    geom_bar(stat = 'identity') + 
    geom_text(aes(label = paste0(CountPer, '%'),
                  y = Labelpos),
              size = 3) +
    coord_flip() + ggtitle('', subtitle = 'HTO reads') +
    xlab('') + ylab('Summed counts') + scale_fill_discrete(name = 'Classification') +
    scale_fill_manual(values = c(my.cols[['Doublet']],my.cols[['Singlet']],my.cols[['Negative']],my.cols[['Uncalled']])) +
    labs(fill = 'Classification') + 
    theme_minimal(base_size = base.size) +
    theme(text = element_text(family = plotting.font))
  
  plot.comb <- cowplot::plot_grid(p.rna + NoLegend(),p.hto,ncol = 2,rel_widths = c(2,1.5))
  
}

print(plot.comb)
```

## UMAP {.tabset}
```{r, results='asis', cache.lazy = FALSE}
for (i in seq(n.pools)) {
  catHeader(pool.table[['Index (10x)']][i], 3)
  
  mat.files.10x <- file.path(dir.proj,'scRNAseq','03_PipelineOut',com.ID,'10x',pool.table[['Index (10x)']][i],'res')
  mat.files.hto <- file.path(dir.proj,'scRNAseq','03_PipelineOut',com.ID,'hto',pool.table[['Index (HTO)']][i],'res')
    
  featDump.10x <- suppressMessages(read_delim(file.path(mat.files.10x,'featureDump.txt'), delim = '\t'))
  featDump.hto <- suppressMessages(read_delim(file.path(mat.files.hto,'featureDump.txt'), delim = '\t'))
  
  meta.data <- read.csv(file.path(dir.pipe.outs,pool.table[['Index (10x)']][i],'seurat-full-metadata.csv'))
  
  cells.negat.inter <- rownames(meta.data[meta.data[['HTO_mcl_classification.global']] == 'Negative',])
  cells.doubl.inter <- rownames(meta.data[meta.data[['HTO_mcl_classification.global']] == 'Doublet',])
  cells.singl.inter <- rownames(meta.data[meta.data[['HTO_mcl_classification.global']] == 'Singlet',])
  
  common.CBs <- intersect(featDump.10x$CB,featDump.hto$CB)
  
  featDump.10x %>% 
    filter(CB %in% common.CBs) %>% 
    arrange(CB) -> featDump.10x
  
  featDump.hto %>% 
    filter(CB %in% common.CBs) %>% 
    arrange(CB) -> featDump.hto
  
  common.CBs.sort <- sort(common.CBs)
  
  tmpdf <- ifelse(common.CBs.sort %in% cells.negat.inter, 'Negative',
                  ifelse(common.CBs.sort %in% cells.doubl.inter, 'Doublet',
                         ifelse(common.CBs.sort %in% cells.singl.inter, 'Singlet', 'Uncalled')))
  
  p <- ggplot(mapping = aes(x = featDump.10x$DeduplicatedReads,
                            y = featDump.hto$DeduplicatedReads,
                            col = tmpdf)) +
    geom_point() + scale_x_log10() + scale_y_log10() +
    scale_color_manual(values = c(my.cols[['Doublet']],my.cols[['Negative']],my.cols[['Singlet']],my.cols[['Uncalled']])) +
    labs(x = 'UMIs (RNA)',
         y = 'UMIs (HTO)',
         col = '') +
    theme_minimal(base_size = base.size)
  
  print(p)
}
```
